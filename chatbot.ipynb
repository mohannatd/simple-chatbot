{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U-gz-vB9su2",
        "outputId": "3fef836f-fe6d-418c-c17b-0f80b4f71aee"
      },
      "source": [
        "pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c7/435f49c0ac6bec031d1aba4daf94dc21dc08a9db329692cdb77faac51cea/pyspellchecker-0.6.2-py3-none-any.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 17.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZDwYlKFuG6j",
        "outputId": "2795c7dd-0c16-4890-f1a8-324744d7ce6b"
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtvvHZz4XzHP",
        "outputId": "a7081227-96ab-4118-af04-151f423320bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "with open('/content/gdrive/My Drive/Datasets/Intent2.json') as file:\n",
        "    data = json.load(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Cf0gXr8hM-",
        "outputId": "b6cc0643-41b8-4806-bc77-332b1a19337c"
      },
      "source": [
        "data['intents'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': {'clear': False, 'in': '', 'out': 'GreetingUserRequest'},\n",
              " 'entities': [],\n",
              " 'entityType': 'NA',\n",
              " 'extension': {'entities': False, 'function': '', 'responses': []},\n",
              " 'intent': 'Greeting',\n",
              " 'responses': ['Hi human, please tell me your GeniSys user',\n",
              "  'Hello human, please tell me your GeniSys user',\n",
              "  'Hola human, please tell me your GeniSys user'],\n",
              " 'text': ['Hi',\n",
              "  'Hi there',\n",
              "  'Hola',\n",
              "  'Hello',\n",
              "  'Hello there',\n",
              "  'Hya',\n",
              "  'Hya there']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzX4CAhVBxc-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ9Q_-cu7TYt"
      },
      "source": [
        "# Remove Stopwords (Stopwords like 'a', 'the', ... )\n",
        "\n",
        "StopWordsList = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in str(text).split() if word not in StopWordsList])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROj8ySSQ9iCk"
      },
      "source": [
        "# Spleling correction\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjYQZ1oKZlcx"
      },
      "source": [
        "# Word Tokenizing and define X and Y\n",
        "\n",
        "words = []      # all of words that are in sentences\n",
        "all_labels = [] # intents\n",
        "sentences = []  # input sentences(X)\n",
        "y = []          # label that match to each sentence\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['text']:\n",
        "      pattern_stopwords = remove_stopwords(pattern)\n",
        "      pattern_spelling = remove_stopwords(pattern_stopwords)\n",
        "      wrds = nltk.word_tokenize(pattern_spelling)\n",
        "      words.extend(wrds)\n",
        "      sentences.append(wrds)\n",
        "      y.append(intent[\"intent\"])\n",
        "        \n",
        "    if intent['intent'] not in all_labels:\n",
        "        all_labels.append(intent['intent'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUZCF9JeXet_"
      },
      "source": [
        "# Stemming\n",
        "\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "words = [stemmer.stem(w.lower()) for w in words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "all_labels = sorted(all_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY44ztU4dL0a"
      },
      "source": [
        "# Make bag of words\n",
        "\n",
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(all_labels))]\n",
        "\n",
        "for indx, sentence in enumerate(sentences):\n",
        "\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in sentence]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[all_labels.index(y[indx])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "\n",
        "training = np.array(training)\n",
        "output = np.array(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymXV-G7zwJyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68b67ff-aab2-4c0c-e6ec-0947d43e93d8"
      },
      "source": [
        "# make MLP model\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu', input_dim=len(training[0])))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dense(len(output[0]), activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='rmsprop', metrics='accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 128)               13312     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 22)                1430      \n",
            "=================================================================\n",
            "Total params: 22,998\n",
            "Trainable params: 22,998\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsLh5vtBxi6l",
        "outputId": "210119f0-111d-4b84-f500-024bc0aada12"
      },
      "source": [
        "model.fit(training, output, epochs=500, batch_size=16, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.1425e-04 - accuracy: 0.9912 - val_loss: 2.6455e-09 - val_accuracy: 1.0000\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1270e-04 - accuracy: 0.9825 - val_loss: 2.6867e-09 - val_accuracy: 1.0000\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1386e-04 - accuracy: 0.9912 - val_loss: 2.7197e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1178e-04 - accuracy: 0.9825 - val_loss: 2.7349e-09 - val_accuracy: 1.0000\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1215e-04 - accuracy: 0.9825 - val_loss: 2.7826e-09 - val_accuracy: 1.0000\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9954e-04 - accuracy: 0.9912 - val_loss: 2.8598e-09 - val_accuracy: 1.0000\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1786e-04 - accuracy: 0.9825 - val_loss: 2.9128e-09 - val_accuracy: 1.0000\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1365e-04 - accuracy: 0.9825 - val_loss: 2.8608e-09 - val_accuracy: 1.0000\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1236e-04 - accuracy: 0.9825 - val_loss: 2.8738e-09 - val_accuracy: 1.0000\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1246e-04 - accuracy: 0.9912 - val_loss: 2.9051e-09 - val_accuracy: 1.0000\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1310e-04 - accuracy: 0.9912 - val_loss: 2.9887e-09 - val_accuracy: 1.0000\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9948e-04 - accuracy: 0.9912 - val_loss: 3.0198e-09 - val_accuracy: 1.0000\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1755e-04 - accuracy: 0.9825 - val_loss: 3.1158e-09 - val_accuracy: 1.0000\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1289e-04 - accuracy: 0.9825 - val_loss: 3.1475e-09 - val_accuracy: 1.0000\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1344e-04 - accuracy: 0.9825 - val_loss: 3.1050e-09 - val_accuracy: 1.0000\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1217e-04 - accuracy: 0.9825 - val_loss: 3.1371e-09 - val_accuracy: 1.0000\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1302e-04 - accuracy: 0.9912 - val_loss: 3.1853e-09 - val_accuracy: 1.0000\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1323e-04 - accuracy: 0.9825 - val_loss: 3.2257e-09 - val_accuracy: 1.0000\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1322e-04 - accuracy: 0.9825 - val_loss: 3.2392e-09 - val_accuracy: 1.0000\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1448e-04 - accuracy: 0.9825 - val_loss: 3.3166e-09 - val_accuracy: 1.0000\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1217e-04 - accuracy: 0.9825 - val_loss: 3.3426e-09 - val_accuracy: 1.0000\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1399e-04 - accuracy: 0.9912 - val_loss: 3.3155e-09 - val_accuracy: 1.0000\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0314e-04 - accuracy: 0.9912 - val_loss: 3.4016e-09 - val_accuracy: 1.0000\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0460e-04 - accuracy: 0.9912 - val_loss: 3.4450e-09 - val_accuracy: 1.0000\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0512e-04 - accuracy: 0.9825 - val_loss: 3.4978e-09 - val_accuracy: 1.0000\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9955e-04 - accuracy: 0.9912 - val_loss: 3.5972e-09 - val_accuracy: 1.0000\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9947e-04 - accuracy: 0.9912 - val_loss: 3.7366e-09 - val_accuracy: 1.0000\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1585e-04 - accuracy: 0.9912 - val_loss: 3.7032e-09 - val_accuracy: 1.0000\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1392e-04 - accuracy: 0.9912 - val_loss: 3.6558e-09 - val_accuracy: 1.0000\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1264e-04 - accuracy: 0.9825 - val_loss: 3.6707e-09 - val_accuracy: 1.0000\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1302e-04 - accuracy: 0.9825 - val_loss: 3.6168e-09 - val_accuracy: 1.0000\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0724e-04 - accuracy: 0.9912 - val_loss: 3.7098e-09 - val_accuracy: 1.0000\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0464e-04 - accuracy: 0.9912 - val_loss: 3.7932e-09 - val_accuracy: 1.0000\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0622e-04 - accuracy: 0.9912 - val_loss: 3.8691e-09 - val_accuracy: 1.0000\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0876e-04 - accuracy: 0.9912 - val_loss: 3.7955e-09 - val_accuracy: 1.0000\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1060e-04 - accuracy: 0.9912 - val_loss: 3.9025e-09 - val_accuracy: 1.0000\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9961e-04 - accuracy: 0.9912 - val_loss: 4.0185e-09 - val_accuracy: 1.0000\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1549e-04 - accuracy: 0.9825 - val_loss: 4.0149e-09 - val_accuracy: 1.0000\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1965e-04 - accuracy: 0.9912 - val_loss: 4.0317e-09 - val_accuracy: 1.0000\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9946e-04 - accuracy: 0.9912 - val_loss: 4.1557e-09 - val_accuracy: 1.0000\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.2349e-04 - accuracy: 0.9912 - val_loss: 4.1382e-09 - val_accuracy: 1.0000\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1879e-04 - accuracy: 0.9912 - val_loss: 4.2414e-09 - val_accuracy: 1.0000\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9953e-04 - accuracy: 0.9912 - val_loss: 4.4027e-09 - val_accuracy: 1.0000\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1689e-04 - accuracy: 0.9825 - val_loss: 4.5738e-09 - val_accuracy: 1.0000\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1539e-04 - accuracy: 0.9912 - val_loss: 4.5280e-09 - val_accuracy: 1.0000\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9933e-04 - accuracy: 0.9912 - val_loss: 4.6248e-09 - val_accuracy: 1.0000\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1574e-04 - accuracy: 0.9825 - val_loss: 4.5801e-09 - val_accuracy: 1.0000\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1260e-04 - accuracy: 0.9825 - val_loss: 4.6520e-09 - val_accuracy: 1.0000\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1279e-04 - accuracy: 0.9912 - val_loss: 4.6520e-09 - val_accuracy: 1.0000\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1234e-04 - accuracy: 0.9825 - val_loss: 4.7036e-09 - val_accuracy: 1.0000\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1306e-04 - accuracy: 0.9912 - val_loss: 4.7146e-09 - val_accuracy: 1.0000\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1334e-04 - accuracy: 0.9825 - val_loss: 4.7823e-09 - val_accuracy: 1.0000\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1112e-04 - accuracy: 0.9912 - val_loss: 5.1272e-09 - val_accuracy: 1.0000\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0228e-04 - accuracy: 0.9912 - val_loss: 5.1517e-09 - val_accuracy: 1.0000\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0335e-04 - accuracy: 0.9912 - val_loss: 5.1685e-09 - val_accuracy: 1.0000\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0549e-04 - accuracy: 0.9912 - val_loss: 5.2007e-09 - val_accuracy: 1.0000\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0784e-04 - accuracy: 0.9825 - val_loss: 5.1848e-09 - val_accuracy: 1.0000\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0932e-04 - accuracy: 0.9912 - val_loss: 5.1451e-09 - val_accuracy: 1.0000\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0990e-04 - accuracy: 0.9825 - val_loss: 5.1424e-09 - val_accuracy: 1.0000\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1098e-04 - accuracy: 0.9912 - val_loss: 5.1709e-09 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1148e-04 - accuracy: 0.9825 - val_loss: 5.1642e-09 - val_accuracy: 1.0000\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9946e-04 - accuracy: 0.9912 - val_loss: 5.2923e-09 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1458e-04 - accuracy: 0.9825 - val_loss: 5.2157e-09 - val_accuracy: 1.0000\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1310e-04 - accuracy: 0.9912 - val_loss: 5.1856e-09 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1240e-04 - accuracy: 0.9825 - val_loss: 5.1885e-09 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1071e-04 - accuracy: 0.9912 - val_loss: 5.1625e-09 - val_accuracy: 1.0000\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1144e-04 - accuracy: 0.9912 - val_loss: 5.1362e-09 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1145e-04 - accuracy: 0.9912 - val_loss: 5.1569e-09 - val_accuracy: 1.0000\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1059e-04 - accuracy: 0.9912 - val_loss: 5.1694e-09 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1143e-04 - accuracy: 0.9912 - val_loss: 5.2300e-09 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1354e-04 - accuracy: 0.9912 - val_loss: 5.3252e-09 - val_accuracy: 1.0000\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1168e-04 - accuracy: 0.9912 - val_loss: 5.3124e-09 - val_accuracy: 1.0000\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1124e-04 - accuracy: 0.9825 - val_loss: 5.3367e-09 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1008e-04 - accuracy: 0.9825 - val_loss: 5.3630e-09 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1123e-04 - accuracy: 0.9912 - val_loss: 5.4260e-09 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1172e-04 - accuracy: 0.9825 - val_loss: 5.4515e-09 - val_accuracy: 1.0000\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1146e-04 - accuracy: 0.9825 - val_loss: 5.4421e-09 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1092e-04 - accuracy: 0.9912 - val_loss: 5.4530e-09 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1064e-04 - accuracy: 0.9912 - val_loss: 5.5202e-09 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9950e-04 - accuracy: 0.9912 - val_loss: 5.7481e-09 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1375e-04 - accuracy: 0.9912 - val_loss: 5.7885e-09 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1283e-04 - accuracy: 0.9825 - val_loss: 5.8721e-09 - val_accuracy: 1.0000\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1114e-04 - accuracy: 0.9825 - val_loss: 5.8772e-09 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0996e-04 - accuracy: 0.9912 - val_loss: 5.8587e-09 - val_accuracy: 1.0000\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1123e-04 - accuracy: 0.9912 - val_loss: 5.9033e-09 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1171e-04 - accuracy: 0.9825 - val_loss: 5.9232e-09 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1017e-04 - accuracy: 0.9825 - val_loss: 6.0126e-09 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1182e-04 - accuracy: 0.9825 - val_loss: 6.0289e-09 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1049e-04 - accuracy: 0.9825 - val_loss: 6.0556e-09 - val_accuracy: 1.0000\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0990e-04 - accuracy: 0.9825 - val_loss: 6.7107e-09 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1157e-04 - accuracy: 0.9825 - val_loss: 6.6748e-09 - val_accuracy: 1.0000\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1090e-04 - accuracy: 0.9825 - val_loss: 6.7980e-09 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1159e-04 - accuracy: 0.9912 - val_loss: 6.8442e-09 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0940e-04 - accuracy: 0.9825 - val_loss: 6.9373e-09 - val_accuracy: 1.0000\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1080e-04 - accuracy: 0.9825 - val_loss: 7.0641e-09 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1015e-04 - accuracy: 0.9825 - val_loss: 7.1308e-09 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1100e-04 - accuracy: 0.9912 - val_loss: 7.1221e-09 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0944e-04 - accuracy: 0.9912 - val_loss: 7.1560e-09 - val_accuracy: 1.0000\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1003e-04 - accuracy: 0.9825 - val_loss: 7.1630e-09 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1110e-04 - accuracy: 0.9825 - val_loss: 7.1813e-09 - val_accuracy: 1.0000\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1230e-04 - accuracy: 0.9825 - val_loss: 7.1698e-09 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1029e-04 - accuracy: 0.9912 - val_loss: 7.2619e-09 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1117e-04 - accuracy: 0.9912 - val_loss: 7.2897e-09 - val_accuracy: 1.0000\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1153e-04 - accuracy: 0.9912 - val_loss: 7.3260e-09 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0904e-04 - accuracy: 0.9825 - val_loss: 7.4063e-09 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9953e-04 - accuracy: 0.9912 - val_loss: 7.6895e-09 - val_accuracy: 1.0000\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1323e-04 - accuracy: 0.9825 - val_loss: 7.7673e-09 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1134e-04 - accuracy: 0.9825 - val_loss: 7.8431e-09 - val_accuracy: 1.0000\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1098e-04 - accuracy: 0.9912 - val_loss: 7.8754e-09 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9946e-04 - accuracy: 0.9912 - val_loss: 8.1584e-09 - val_accuracy: 1.0000\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1370e-04 - accuracy: 0.9912 - val_loss: 8.1351e-09 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3.9940e-04 - accuracy: 0.9912 - val_loss: 8.3758e-09 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1330e-04 - accuracy: 0.9825 - val_loss: 8.4137e-09 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1124e-04 - accuracy: 0.9912 - val_loss: 8.5620e-09 - val_accuracy: 1.0000\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9936e-04 - accuracy: 0.9912 - val_loss: 8.7926e-09 - val_accuracy: 1.0000\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1498e-04 - accuracy: 0.9825 - val_loss: 8.5504e-09 - val_accuracy: 1.0000\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1028e-04 - accuracy: 0.9825 - val_loss: 8.6755e-09 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1173e-04 - accuracy: 0.9825 - val_loss: 8.7773e-09 - val_accuracy: 1.0000\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0962e-04 - accuracy: 0.9912 - val_loss: 8.7829e-09 - val_accuracy: 1.0000\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0965e-04 - accuracy: 0.9912 - val_loss: 8.8356e-09 - val_accuracy: 1.0000\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9940e-04 - accuracy: 0.9912 - val_loss: 9.1111e-09 - val_accuracy: 1.0000\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1342e-04 - accuracy: 0.9912 - val_loss: 9.0753e-09 - val_accuracy: 1.0000\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0988e-04 - accuracy: 0.9912 - val_loss: 8.7046e-09 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1109e-04 - accuracy: 0.9825 - val_loss: 8.7573e-09 - val_accuracy: 1.0000\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0989e-04 - accuracy: 0.9825 - val_loss: 8.9640e-09 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0967e-04 - accuracy: 0.9912 - val_loss: 9.0119e-09 - val_accuracy: 1.0000\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0897e-04 - accuracy: 0.9912 - val_loss: 8.6773e-09 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0933e-04 - accuracy: 0.9825 - val_loss: 8.5076e-09 - val_accuracy: 1.0000\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0914e-04 - accuracy: 0.9825 - val_loss: 8.6379e-09 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0933e-04 - accuracy: 0.9825 - val_loss: 8.6516e-09 - val_accuracy: 1.0000\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1108e-04 - accuracy: 0.9912 - val_loss: 8.7678e-09 - val_accuracy: 1.0000\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1013e-04 - accuracy: 0.9912 - val_loss: 8.8395e-09 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1053e-04 - accuracy: 0.9825 - val_loss: 9.0291e-09 - val_accuracy: 1.0000\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0952e-04 - accuracy: 0.9825 - val_loss: 9.1038e-09 - val_accuracy: 1.0000\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0997e-04 - accuracy: 0.9825 - val_loss: 9.3402e-09 - val_accuracy: 1.0000\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.1039e-04 - accuracy: 0.9912 - val_loss: 9.2677e-09 - val_accuracy: 1.0000\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0911e-04 - accuracy: 0.9912 - val_loss: 9.6221e-09 - val_accuracy: 1.0000\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1016e-04 - accuracy: 0.9912 - val_loss: 9.6258e-09 - val_accuracy: 1.0000\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0871e-04 - accuracy: 0.9912 - val_loss: 9.4443e-09 - val_accuracy: 1.0000\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0898e-04 - accuracy: 0.9825 - val_loss: 9.6423e-09 - val_accuracy: 1.0000\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0911e-04 - accuracy: 0.9912 - val_loss: 9.6635e-09 - val_accuracy: 1.0000\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0898e-04 - accuracy: 0.9912 - val_loss: 9.8102e-09 - val_accuracy: 1.0000\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0952e-04 - accuracy: 0.9912 - val_loss: 1.0441e-08 - val_accuracy: 1.0000\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1057e-04 - accuracy: 0.9912 - val_loss: 1.0879e-08 - val_accuracy: 1.0000\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0980e-04 - accuracy: 0.9912 - val_loss: 1.0868e-08 - val_accuracy: 1.0000\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1056e-04 - accuracy: 0.9825 - val_loss: 1.0817e-08 - val_accuracy: 1.0000\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0860e-04 - accuracy: 0.9912 - val_loss: 1.1224e-08 - val_accuracy: 1.0000\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1055e-04 - accuracy: 0.9912 - val_loss: 1.1211e-08 - val_accuracy: 1.0000\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1053e-04 - accuracy: 0.9825 - val_loss: 1.1267e-08 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0864e-04 - accuracy: 0.9825 - val_loss: 1.1375e-08 - val_accuracy: 1.0000\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0931e-04 - accuracy: 0.9825 - val_loss: 1.1404e-08 - val_accuracy: 1.0000\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0952e-04 - accuracy: 0.9912 - val_loss: 1.1418e-08 - val_accuracy: 1.0000\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1015e-04 - accuracy: 0.9912 - val_loss: 1.1406e-08 - val_accuracy: 1.0000\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0950e-04 - accuracy: 0.9825 - val_loss: 1.1380e-08 - val_accuracy: 1.0000\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0970e-04 - accuracy: 0.9825 - val_loss: 1.1401e-08 - val_accuracy: 1.0000\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0896e-04 - accuracy: 0.9825 - val_loss: 1.1460e-08 - val_accuracy: 1.0000\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0918e-04 - accuracy: 0.9912 - val_loss: 1.1572e-08 - val_accuracy: 1.0000\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0931e-04 - accuracy: 0.9825 - val_loss: 1.1778e-08 - val_accuracy: 1.0000\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1006e-04 - accuracy: 0.9825 - val_loss: 1.1773e-08 - val_accuracy: 1.0000\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0905e-04 - accuracy: 0.9825 - val_loss: 1.1910e-08 - val_accuracy: 1.0000\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1021e-04 - accuracy: 0.9825 - val_loss: 1.1935e-08 - val_accuracy: 1.0000\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0908e-04 - accuracy: 0.9825 - val_loss: 1.1739e-08 - val_accuracy: 1.0000\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0922e-04 - accuracy: 0.9825 - val_loss: 1.2515e-08 - val_accuracy: 1.0000\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0910e-04 - accuracy: 0.9912 - val_loss: 1.2535e-08 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0856e-04 - accuracy: 0.9912 - val_loss: 1.2129e-08 - val_accuracy: 1.0000\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1014e-04 - accuracy: 0.9912 - val_loss: 1.2567e-08 - val_accuracy: 1.0000\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0926e-04 - accuracy: 0.9825 - val_loss: 1.2128e-08 - val_accuracy: 1.0000\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9955e-04 - accuracy: 0.9912 - val_loss: 1.2579e-08 - val_accuracy: 1.0000\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0290e-04 - accuracy: 0.9912 - val_loss: 1.2869e-08 - val_accuracy: 1.0000\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0524e-04 - accuracy: 0.9912 - val_loss: 1.3185e-08 - val_accuracy: 1.0000\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9946e-04 - accuracy: 0.9912 - val_loss: 1.3403e-08 - val_accuracy: 1.0000\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9939e-04 - accuracy: 0.9912 - val_loss: 1.3897e-08 - val_accuracy: 1.0000\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9931e-04 - accuracy: 0.9912 - val_loss: 1.4635e-08 - val_accuracy: 1.0000\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1339e-04 - accuracy: 0.9912 - val_loss: 1.4414e-08 - val_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1162e-04 - accuracy: 0.9912 - val_loss: 1.4337e-08 - val_accuracy: 1.0000\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1054e-04 - accuracy: 0.9912 - val_loss: 1.3961e-08 - val_accuracy: 1.0000\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0906e-04 - accuracy: 0.9825 - val_loss: 1.4132e-08 - val_accuracy: 1.0000\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0915e-04 - accuracy: 0.9825 - val_loss: 1.4108e-08 - val_accuracy: 1.0000\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1066e-04 - accuracy: 0.9912 - val_loss: 1.4360e-08 - val_accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0902e-04 - accuracy: 0.9825 - val_loss: 1.4339e-08 - val_accuracy: 1.0000\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0927e-04 - accuracy: 0.9912 - val_loss: 1.4571e-08 - val_accuracy: 1.0000\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0875e-04 - accuracy: 0.9825 - val_loss: 1.5443e-08 - val_accuracy: 1.0000\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0867e-04 - accuracy: 0.9912 - val_loss: 1.5593e-08 - val_accuracy: 1.0000\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0878e-04 - accuracy: 0.9912 - val_loss: 1.5849e-08 - val_accuracy: 1.0000\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0852e-04 - accuracy: 0.9912 - val_loss: 1.5813e-08 - val_accuracy: 1.0000\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0892e-04 - accuracy: 0.9912 - val_loss: 1.5843e-08 - val_accuracy: 1.0000\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0914e-04 - accuracy: 0.9825 - val_loss: 1.5873e-08 - val_accuracy: 1.0000\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0877e-04 - accuracy: 0.9825 - val_loss: 1.6068e-08 - val_accuracy: 1.0000\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1015e-04 - accuracy: 0.9912 - val_loss: 1.6426e-08 - val_accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0907e-04 - accuracy: 0.9825 - val_loss: 1.6563e-08 - val_accuracy: 1.0000\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0969e-04 - accuracy: 0.9825 - val_loss: 1.6819e-08 - val_accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1220e-04 - accuracy: 0.9825 - val_loss: 1.6251e-08 - val_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0167e-04 - accuracy: 0.9912 - val_loss: 1.6361e-08 - val_accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0331e-04 - accuracy: 0.9912 - val_loss: 1.6554e-08 - val_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0382e-04 - accuracy: 0.9912 - val_loss: 1.6776e-08 - val_accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0526e-04 - accuracy: 0.9912 - val_loss: 1.7236e-08 - val_accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0765e-04 - accuracy: 0.9912 - val_loss: 1.7230e-08 - val_accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1006e-04 - accuracy: 0.9912 - val_loss: 1.7142e-08 - val_accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0995e-04 - accuracy: 0.9912 - val_loss: 1.7912e-08 - val_accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0972e-04 - accuracy: 0.9825 - val_loss: 1.7897e-08 - val_accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0940e-04 - accuracy: 0.9825 - val_loss: 1.7975e-08 - val_accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1077e-04 - accuracy: 0.9912 - val_loss: 1.7934e-08 - val_accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1089e-04 - accuracy: 0.9825 - val_loss: 1.7622e-08 - val_accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9961e-04 - accuracy: 0.9912 - val_loss: 1.8501e-08 - val_accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1599e-04 - accuracy: 0.9825 - val_loss: 1.8669e-08 - val_accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1429e-04 - accuracy: 0.9912 - val_loss: 1.8892e-08 - val_accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1215e-04 - accuracy: 0.9912 - val_loss: 1.9281e-08 - val_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1369e-04 - accuracy: 0.9912 - val_loss: 1.8938e-08 - val_accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1199e-04 - accuracy: 0.9825 - val_loss: 1.9663e-08 - val_accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0939e-04 - accuracy: 0.9912 - val_loss: 1.9509e-08 - val_accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0948e-04 - accuracy: 0.9825 - val_loss: 1.9197e-08 - val_accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0997e-04 - accuracy: 0.9825 - val_loss: 1.9318e-08 - val_accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0975e-04 - accuracy: 0.9825 - val_loss: 1.9177e-08 - val_accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0892e-04 - accuracy: 0.9825 - val_loss: 1.8983e-08 - val_accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1300e-04 - accuracy: 0.9825 - val_loss: 1.9224e-08 - val_accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1178e-04 - accuracy: 0.9825 - val_loss: 1.9323e-08 - val_accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1334e-04 - accuracy: 0.9825 - val_loss: 2.0062e-08 - val_accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1020e-04 - accuracy: 0.9825 - val_loss: 2.0011e-08 - val_accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0818e-04 - accuracy: 0.9912 - val_loss: 1.9981e-08 - val_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0893e-04 - accuracy: 0.9825 - val_loss: 1.9931e-08 - val_accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0958e-04 - accuracy: 0.9825 - val_loss: 2.0129e-08 - val_accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1122e-04 - accuracy: 0.9912 - val_loss: 1.9963e-08 - val_accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0926e-04 - accuracy: 0.9912 - val_loss: 1.9932e-08 - val_accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0876e-04 - accuracy: 0.9912 - val_loss: 2.0193e-08 - val_accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0938e-04 - accuracy: 0.9912 - val_loss: 2.0410e-08 - val_accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0895e-04 - accuracy: 0.9825 - val_loss: 2.0448e-08 - val_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0198e-04 - accuracy: 0.9912 - val_loss: 2.0870e-08 - val_accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0277e-04 - accuracy: 0.9912 - val_loss: 2.1143e-08 - val_accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0439e-04 - accuracy: 0.9912 - val_loss: 2.1339e-08 - val_accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0627e-04 - accuracy: 0.9912 - val_loss: 2.1692e-08 - val_accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0780e-04 - accuracy: 0.9912 - val_loss: 2.2109e-08 - val_accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0734e-04 - accuracy: 0.9825 - val_loss: 2.2032e-08 - val_accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0872e-04 - accuracy: 0.9825 - val_loss: 2.2303e-08 - val_accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0942e-04 - accuracy: 0.9825 - val_loss: 2.2594e-08 - val_accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0855e-04 - accuracy: 0.9912 - val_loss: 2.2681e-08 - val_accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0954e-04 - accuracy: 0.9825 - val_loss: 2.2854e-08 - val_accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0883e-04 - accuracy: 0.9825 - val_loss: 2.3054e-08 - val_accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0961e-04 - accuracy: 0.9912 - val_loss: 2.4547e-08 - val_accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1012e-04 - accuracy: 0.9912 - val_loss: 2.4338e-08 - val_accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0757e-04 - accuracy: 0.9825 - val_loss: 2.4230e-08 - val_accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0826e-04 - accuracy: 0.9912 - val_loss: 2.4158e-08 - val_accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9932e-04 - accuracy: 0.9912 - val_loss: 2.5162e-08 - val_accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1102e-04 - accuracy: 0.9825 - val_loss: 2.5084e-08 - val_accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9929e-04 - accuracy: 0.9912 - val_loss: 2.5950e-08 - val_accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1219e-04 - accuracy: 0.9825 - val_loss: 2.6039e-08 - val_accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1089e-04 - accuracy: 0.9912 - val_loss: 2.6179e-08 - val_accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1019e-04 - accuracy: 0.9825 - val_loss: 2.6300e-08 - val_accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0913e-04 - accuracy: 0.9912 - val_loss: 2.5967e-08 - val_accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0852e-04 - accuracy: 0.9912 - val_loss: 2.5681e-08 - val_accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0905e-04 - accuracy: 0.9912 - val_loss: 2.5621e-08 - val_accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0874e-04 - accuracy: 0.9825 - val_loss: 2.5812e-08 - val_accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0927e-04 - accuracy: 0.9825 - val_loss: 2.6414e-08 - val_accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0842e-04 - accuracy: 0.9825 - val_loss: 2.6482e-08 - val_accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0944e-04 - accuracy: 0.9912 - val_loss: 2.5957e-08 - val_accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0963e-04 - accuracy: 0.9912 - val_loss: 2.4168e-08 - val_accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1173e-04 - accuracy: 0.9825 - val_loss: 2.4367e-08 - val_accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1046e-04 - accuracy: 0.9912 - val_loss: 2.5012e-08 - val_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.1146e-04 - accuracy: 0.9825 - val_loss: 2.5129e-08 - val_accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1035e-04 - accuracy: 0.9825 - val_loss: 2.5534e-08 - val_accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9925e-04 - accuracy: 0.9912 - val_loss: 2.6133e-08 - val_accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1359e-04 - accuracy: 0.9825 - val_loss: 2.6387e-08 - val_accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1150e-04 - accuracy: 0.9912 - val_loss: 2.6785e-08 - val_accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9928e-04 - accuracy: 0.9912 - val_loss: 2.7398e-08 - val_accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.1438e-04 - accuracy: 0.9912 - val_loss: 2.8919e-08 - val_accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9937e-04 - accuracy: 0.9912 - val_loss: 2.9351e-08 - val_accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1153e-04 - accuracy: 0.9825 - val_loss: 2.9137e-08 - val_accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0963e-04 - accuracy: 0.9825 - val_loss: 2.8717e-08 - val_accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0841e-04 - accuracy: 0.9912 - val_loss: 2.8836e-08 - val_accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0848e-04 - accuracy: 0.9825 - val_loss: 2.8426e-08 - val_accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0991e-04 - accuracy: 0.9912 - val_loss: 2.7634e-08 - val_accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0165e-04 - accuracy: 0.9912 - val_loss: 2.8387e-08 - val_accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0238e-04 - accuracy: 0.9825 - val_loss: 2.8593e-08 - val_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0384e-04 - accuracy: 0.9912 - val_loss: 2.9636e-08 - val_accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0495e-04 - accuracy: 0.9912 - val_loss: 2.9908e-08 - val_accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0664e-04 - accuracy: 0.9912 - val_loss: 3.0217e-08 - val_accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0737e-04 - accuracy: 0.9912 - val_loss: 3.0503e-08 - val_accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0732e-04 - accuracy: 0.9825 - val_loss: 3.0439e-08 - val_accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0891e-04 - accuracy: 0.9825 - val_loss: 3.0624e-08 - val_accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0780e-04 - accuracy: 0.9825 - val_loss: 3.1039e-08 - val_accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9929e-04 - accuracy: 0.9912 - val_loss: 3.2091e-08 - val_accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9921e-04 - accuracy: 0.9912 - val_loss: 3.3489e-08 - val_accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1261e-04 - accuracy: 0.9912 - val_loss: 3.3872e-08 - val_accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1056e-04 - accuracy: 0.9912 - val_loss: 3.2766e-08 - val_accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0981e-04 - accuracy: 0.9912 - val_loss: 3.2917e-08 - val_accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0911e-04 - accuracy: 0.9912 - val_loss: 3.3242e-08 - val_accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0821e-04 - accuracy: 0.9825 - val_loss: 3.2616e-08 - val_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0877e-04 - accuracy: 0.9825 - val_loss: 3.3714e-08 - val_accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0759e-04 - accuracy: 0.9825 - val_loss: 3.3753e-08 - val_accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0764e-04 - accuracy: 0.9825 - val_loss: 3.4093e-08 - val_accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.0828e-04 - accuracy: 0.9825 - val_loss: 3.3845e-08 - val_accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0753e-04 - accuracy: 0.9912 - val_loss: 3.2772e-08 - val_accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.1211e-04 - accuracy: 0.9912 - val_loss: 3.2807e-08 - val_accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.1171e-04 - accuracy: 0.9825 - val_loss: 3.3451e-08 - val_accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.1162e-04 - accuracy: 0.9912 - val_loss: 3.5413e-08 - val_accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0305e-04 - accuracy: 0.9912 - val_loss: 4.2987e-08 - val_accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 4.0249e-04 - accuracy: 0.9912 - val_loss: 4.1902e-08 - val_accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0299e-04 - accuracy: 0.9912 - val_loss: 4.1366e-08 - val_accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0396e-04 - accuracy: 0.9912 - val_loss: 4.0827e-08 - val_accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 3.9984e-04 - accuracy: 0.9912 - val_loss: 4.0680e-08 - val_accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.0746e-04 - accuracy: 0.9912 - val_loss: 3.9066e-08 - val_accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 4.0743e-04 - accuracy: 0.9912 - val_loss: 3.9149e-08 - val_accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 4.0802e-04 - accuracy: 0.9912 - val_loss: 3.8612e-08 - val_accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0863e-04 - accuracy: 0.9912 - val_loss: 3.6621e-08 - val_accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0917e-04 - accuracy: 0.9912 - val_loss: 3.6351e-08 - val_accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 4.0843e-04 - accuracy: 0.9912 - val_loss: 3.5432e-08 - val_accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.0868e-04 - accuracy: 0.9912 - val_loss: 3.4729e-08 - val_accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 3.9957e-04 - accuracy: 0.9912 - val_loss: 3.5612e-08 - val_accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.1117e-04 - accuracy: 0.9912 - val_loss: 3.5371e-08 - val_accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.1035e-04 - accuracy: 0.9912 - val_loss: 3.5180e-08 - val_accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 4.0802e-04 - accuracy: 0.9912 - val_loss: 3.5299e-08 - val_accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0930e-04 - accuracy: 0.9912 - val_loss: 3.4543e-08 - val_accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0796e-04 - accuracy: 0.9912 - val_loss: 3.4414e-08 - val_accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0846e-04 - accuracy: 0.9912 - val_loss: 3.4202e-08 - val_accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0763e-04 - accuracy: 0.9912 - val_loss: 3.3999e-08 - val_accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9941e-04 - accuracy: 0.9912 - val_loss: 3.5003e-08 - val_accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1031e-04 - accuracy: 0.9912 - val_loss: 3.5259e-08 - val_accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0891e-04 - accuracy: 0.9912 - val_loss: 3.5213e-08 - val_accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0801e-04 - accuracy: 0.9912 - val_loss: 3.4851e-08 - val_accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0815e-04 - accuracy: 0.9825 - val_loss: 4.1069e-08 - val_accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0166e-04 - accuracy: 0.9912 - val_loss: 4.1144e-08 - val_accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0277e-04 - accuracy: 0.9912 - val_loss: 4.1284e-08 - val_accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0393e-04 - accuracy: 0.9912 - val_loss: 4.0774e-08 - val_accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9946e-04 - accuracy: 0.9912 - val_loss: 4.1286e-08 - val_accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9941e-04 - accuracy: 0.9912 - val_loss: 4.1947e-08 - val_accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0937e-04 - accuracy: 0.9912 - val_loss: 4.0857e-08 - val_accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0822e-04 - accuracy: 0.9912 - val_loss: 3.9556e-08 - val_accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0901e-04 - accuracy: 0.9912 - val_loss: 4.0016e-08 - val_accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0828e-04 - accuracy: 0.9912 - val_loss: 4.0110e-08 - val_accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0782e-04 - accuracy: 0.9912 - val_loss: 3.9724e-08 - val_accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0742e-04 - accuracy: 0.9912 - val_loss: 3.9935e-08 - val_accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9941e-04 - accuracy: 0.9912 - val_loss: 4.1315e-08 - val_accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1103e-04 - accuracy: 0.9912 - val_loss: 4.1410e-08 - val_accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0798e-04 - accuracy: 0.9912 - val_loss: 4.0885e-08 - val_accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0793e-04 - accuracy: 0.9912 - val_loss: 4.0834e-08 - val_accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0860e-04 - accuracy: 0.9912 - val_loss: 4.0783e-08 - val_accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0809e-04 - accuracy: 0.9912 - val_loss: 4.0631e-08 - val_accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0714e-04 - accuracy: 0.9825 - val_loss: 4.0642e-08 - val_accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0722e-04 - accuracy: 0.9825 - val_loss: 4.1323e-08 - val_accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0796e-04 - accuracy: 0.9912 - val_loss: 4.2225e-08 - val_accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0877e-04 - accuracy: 0.9912 - val_loss: 4.3286e-08 - val_accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0765e-04 - accuracy: 0.9912 - val_loss: 4.2774e-08 - val_accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0711e-04 - accuracy: 0.9912 - val_loss: 4.3095e-08 - val_accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0819e-04 - accuracy: 0.9912 - val_loss: 4.3263e-08 - val_accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1405e-04 - accuracy: 0.9825 - val_loss: 4.3222e-08 - val_accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0962e-04 - accuracy: 0.9912 - val_loss: 4.4621e-08 - val_accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0705e-04 - accuracy: 0.9825 - val_loss: 4.5601e-08 - val_accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0752e-04 - accuracy: 0.9825 - val_loss: 4.5835e-08 - val_accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9936e-04 - accuracy: 0.9912 - val_loss: 4.7071e-08 - val_accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0997e-04 - accuracy: 0.9912 - val_loss: 4.6538e-08 - val_accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9941e-04 - accuracy: 0.9912 - val_loss: 4.8128e-08 - val_accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1001e-04 - accuracy: 0.9825 - val_loss: 4.6782e-08 - val_accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0986e-04 - accuracy: 0.9825 - val_loss: 4.6718e-08 - val_accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0743e-04 - accuracy: 0.9912 - val_loss: 4.6972e-08 - val_accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0790e-04 - accuracy: 0.9912 - val_loss: 4.7488e-08 - val_accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0734e-04 - accuracy: 0.9825 - val_loss: 4.8047e-08 - val_accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0680e-04 - accuracy: 0.9825 - val_loss: 4.8758e-08 - val_accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0719e-04 - accuracy: 0.9825 - val_loss: 4.9528e-08 - val_accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0717e-04 - accuracy: 0.9912 - val_loss: 4.9818e-08 - val_accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0763e-04 - accuracy: 0.9912 - val_loss: 5.0114e-08 - val_accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9935e-04 - accuracy: 0.9912 - val_loss: 5.2337e-08 - val_accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0974e-04 - accuracy: 0.9825 - val_loss: 5.1189e-08 - val_accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0807e-04 - accuracy: 0.9912 - val_loss: 5.1412e-08 - val_accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0809e-04 - accuracy: 0.9825 - val_loss: 5.5624e-08 - val_accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0114e-04 - accuracy: 0.9912 - val_loss: 5.4907e-08 - val_accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0200e-04 - accuracy: 0.9912 - val_loss: 5.5248e-08 - val_accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0316e-04 - accuracy: 0.9912 - val_loss: 5.6581e-08 - val_accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0468e-04 - accuracy: 0.9912 - val_loss: 5.6545e-08 - val_accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0558e-04 - accuracy: 0.9825 - val_loss: 5.6116e-08 - val_accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9928e-04 - accuracy: 0.9912 - val_loss: 5.8029e-08 - val_accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0900e-04 - accuracy: 0.9825 - val_loss: 5.6439e-08 - val_accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0819e-04 - accuracy: 0.9912 - val_loss: 5.5451e-08 - val_accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1504e-04 - accuracy: 0.9825 - val_loss: 5.6032e-08 - val_accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9917e-04 - accuracy: 0.9912 - val_loss: 5.7697e-08 - val_accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1610e-04 - accuracy: 0.9825 - val_loss: 5.7559e-08 - val_accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1173e-04 - accuracy: 0.9825 - val_loss: 6.2423e-08 - val_accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0775e-04 - accuracy: 0.9825 - val_loss: 6.1648e-08 - val_accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0761e-04 - accuracy: 0.9912 - val_loss: 6.1373e-08 - val_accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0757e-04 - accuracy: 0.9825 - val_loss: 6.1137e-08 - val_accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0689e-04 - accuracy: 0.9912 - val_loss: 6.0630e-08 - val_accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9918e-04 - accuracy: 0.9912 - val_loss: 6.2644e-08 - val_accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.1021e-04 - accuracy: 0.9825 - val_loss: 6.0522e-08 - val_accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0736e-04 - accuracy: 0.9825 - val_loss: 6.0560e-08 - val_accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0783e-04 - accuracy: 0.9912 - val_loss: 6.1634e-08 - val_accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0816e-04 - accuracy: 0.9912 - val_loss: 6.2640e-08 - val_accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0757e-04 - accuracy: 0.9825 - val_loss: 6.4085e-08 - val_accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0765e-04 - accuracy: 0.9825 - val_loss: 6.3613e-08 - val_accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9926e-04 - accuracy: 0.9912 - val_loss: 6.6452e-08 - val_accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.1023e-04 - accuracy: 0.9825 - val_loss: 6.5600e-08 - val_accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0855e-04 - accuracy: 0.9825 - val_loss: 6.6314e-08 - val_accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0816e-04 - accuracy: 0.9825 - val_loss: 7.1151e-08 - val_accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0778e-04 - accuracy: 0.9825 - val_loss: 7.0453e-08 - val_accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 3.9908e-04 - accuracy: 0.9912 - val_loss: 7.1990e-08 - val_accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0989e-04 - accuracy: 0.9912 - val_loss: 6.7856e-08 - val_accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0851e-04 - accuracy: 0.9825 - val_loss: 6.7439e-08 - val_accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0761e-04 - accuracy: 0.9825 - val_loss: 6.6939e-08 - val_accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0692e-04 - accuracy: 0.9912 - val_loss: 6.7612e-08 - val_accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0865e-04 - accuracy: 0.9825 - val_loss: 6.6726e-08 - val_accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.9917e-04 - accuracy: 0.9912 - val_loss: 6.9181e-08 - val_accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0995e-04 - accuracy: 0.9825 - val_loss: 6.9152e-08 - val_accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0760e-04 - accuracy: 0.9825 - val_loss: 6.9284e-08 - val_accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0765e-04 - accuracy: 0.9912 - val_loss: 6.9331e-08 - val_accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0747e-04 - accuracy: 0.9825 - val_loss: 6.9930e-08 - val_accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0679e-04 - accuracy: 0.9912 - val_loss: 7.1768e-08 - val_accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0852e-04 - accuracy: 0.9825 - val_loss: 7.1868e-08 - val_accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0707e-04 - accuracy: 0.9825 - val_loss: 7.1878e-08 - val_accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0668e-04 - accuracy: 0.9825 - val_loss: 7.1348e-08 - val_accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0792e-04 - accuracy: 0.9912 - val_loss: 7.6279e-08 - val_accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0788e-04 - accuracy: 0.9912 - val_loss: 7.5183e-08 - val_accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0731e-04 - accuracy: 0.9912 - val_loss: 7.5191e-08 - val_accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0640e-04 - accuracy: 0.9912 - val_loss: 7.5492e-08 - val_accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0708e-04 - accuracy: 0.9912 - val_loss: 7.6633e-08 - val_accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0724e-04 - accuracy: 0.9912 - val_loss: 7.0920e-08 - val_accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0133e-04 - accuracy: 0.9825 - val_loss: 7.1378e-08 - val_accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0184e-04 - accuracy: 0.9825 - val_loss: 7.1794e-08 - val_accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0296e-04 - accuracy: 0.9912 - val_loss: 7.3236e-08 - val_accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0409e-04 - accuracy: 0.9825 - val_loss: 7.2744e-08 - val_accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0562e-04 - accuracy: 0.9912 - val_loss: 7.3802e-08 - val_accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0560e-04 - accuracy: 0.9912 - val_loss: 7.4745e-08 - val_accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0574e-04 - accuracy: 0.9825 - val_loss: 7.3983e-08 - val_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0626e-04 - accuracy: 0.9825 - val_loss: 7.3124e-08 - val_accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0647e-04 - accuracy: 0.9912 - val_loss: 7.7689e-08 - val_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0745e-04 - accuracy: 0.9825 - val_loss: 7.8627e-08 - val_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0627e-04 - accuracy: 0.9912 - val_loss: 7.8072e-08 - val_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9911e-04 - accuracy: 0.9912 - val_loss: 7.9376e-08 - val_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0870e-04 - accuracy: 0.9912 - val_loss: 7.7403e-08 - val_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0726e-04 - accuracy: 0.9912 - val_loss: 7.7289e-08 - val_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0740e-04 - accuracy: 0.9825 - val_loss: 7.7693e-08 - val_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0590e-04 - accuracy: 0.9912 - val_loss: 7.7534e-08 - val_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0614e-04 - accuracy: 0.9825 - val_loss: 7.6658e-08 - val_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0627e-04 - accuracy: 0.9912 - val_loss: 7.7887e-08 - val_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9914e-04 - accuracy: 0.9912 - val_loss: 7.9926e-08 - val_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0909e-04 - accuracy: 0.9825 - val_loss: 7.8447e-08 - val_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0079e-04 - accuracy: 0.9912 - val_loss: 7.8674e-08 - val_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0180e-04 - accuracy: 0.9912 - val_loss: 7.9627e-08 - val_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0296e-04 - accuracy: 0.9912 - val_loss: 7.8494e-08 - val_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0350e-04 - accuracy: 0.9825 - val_loss: 7.8246e-08 - val_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0483e-04 - accuracy: 0.9912 - val_loss: 7.8954e-08 - val_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0550e-04 - accuracy: 0.9825 - val_loss: 7.9333e-08 - val_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0715e-04 - accuracy: 0.9825 - val_loss: 7.9778e-08 - val_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9916e-04 - accuracy: 0.9912 - val_loss: 8.0573e-08 - val_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0791e-04 - accuracy: 0.9825 - val_loss: 7.9825e-08 - val_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4.0717e-04 - accuracy: 0.9912 - val_loss: 7.9106e-08 - val_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0751e-04 - accuracy: 0.9912 - val_loss: 7.8514e-08 - val_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0646e-04 - accuracy: 0.9912 - val_loss: 7.6688e-08 - val_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0626e-04 - accuracy: 0.9912 - val_loss: 7.6753e-08 - val_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0683e-04 - accuracy: 0.9912 - val_loss: 7.7569e-08 - val_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9928e-04 - accuracy: 0.9912 - val_loss: 8.2016e-08 - val_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0805e-04 - accuracy: 0.9912 - val_loss: 8.1389e-08 - val_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.9925e-04 - accuracy: 0.9912 - val_loss: 8.5112e-08 - val_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0864e-04 - accuracy: 0.9912 - val_loss: 8.1154e-08 - val_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0786e-04 - accuracy: 0.9825 - val_loss: 7.9347e-08 - val_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0094e-04 - accuracy: 0.9912 - val_loss: 8.1069e-08 - val_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0161e-04 - accuracy: 0.9912 - val_loss: 8.2825e-08 - val_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9933e-04 - accuracy: 0.9912 - val_loss: 8.4824e-08 - val_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0434e-04 - accuracy: 0.9912 - val_loss: 8.5831e-08 - val_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0576e-04 - accuracy: 0.9912 - val_loss: 8.6510e-08 - val_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0542e-04 - accuracy: 0.9912 - val_loss: 8.8066e-08 - val_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0655e-04 - accuracy: 0.9825 - val_loss: 8.9270e-08 - val_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.9917e-04 - accuracy: 0.9912 - val_loss: 9.2517e-08 - val_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0779e-04 - accuracy: 0.9825 - val_loss: 9.1808e-08 - val_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0745e-04 - accuracy: 0.9912 - val_loss: 9.0643e-08 - val_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0650e-04 - accuracy: 0.9912 - val_loss: 9.0488e-08 - val_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0592e-04 - accuracy: 0.9912 - val_loss: 9.1421e-08 - val_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0594e-04 - accuracy: 0.9912 - val_loss: 9.2189e-08 - val_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0699e-04 - accuracy: 0.9912 - val_loss: 9.3753e-08 - val_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0637e-04 - accuracy: 0.9825 - val_loss: 9.3944e-08 - val_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0642e-04 - accuracy: 0.9825 - val_loss: 9.5136e-08 - val_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0575e-04 - accuracy: 0.9912 - val_loss: 9.8511e-08 - val_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9929e-04 - accuracy: 0.9912 - val_loss: 1.0165e-07 - val_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9922e-04 - accuracy: 0.9912 - val_loss: 1.0269e-07 - val_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0969e-04 - accuracy: 0.9825 - val_loss: 1.0171e-07 - val_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0683e-04 - accuracy: 0.9825 - val_loss: 1.0097e-07 - val_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0714e-04 - accuracy: 0.9912 - val_loss: 1.0051e-07 - val_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0646e-04 - accuracy: 0.9825 - val_loss: 1.0121e-07 - val_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0594e-04 - accuracy: 0.9825 - val_loss: 1.0092e-07 - val_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0569e-04 - accuracy: 0.9825 - val_loss: 1.0122e-07 - val_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.0610e-04 - accuracy: 0.9825 - val_loss: 1.0216e-07 - val_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0609e-04 - accuracy: 0.9912 - val_loss: 1.0176e-07 - val_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0606e-04 - accuracy: 0.9912 - val_loss: 1.0938e-07 - val_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0616e-04 - accuracy: 0.9825 - val_loss: 1.0856e-07 - val_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0637e-04 - accuracy: 0.9912 - val_loss: 1.1586e-07 - val_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9913e-04 - accuracy: 0.9912 - val_loss: 1.1617e-07 - val_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0160e-04 - accuracy: 0.9912 - val_loss: 1.1640e-07 - val_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0257e-04 - accuracy: 0.9912 - val_loss: 1.1582e-07 - val_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0389e-04 - accuracy: 0.9912 - val_loss: 1.1421e-07 - val_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0422e-04 - accuracy: 0.9912 - val_loss: 1.1474e-07 - val_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0567e-04 - accuracy: 0.9825 - val_loss: 1.1451e-07 - val_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9904e-04 - accuracy: 0.9912 - val_loss: 1.1820e-07 - val_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0772e-04 - accuracy: 0.9912 - val_loss: 1.1668e-07 - val_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0681e-04 - accuracy: 0.9825 - val_loss: 1.1597e-07 - val_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.9905e-04 - accuracy: 0.9912 - val_loss: 1.1815e-07 - val_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9902e-04 - accuracy: 0.9912 - val_loss: 1.2190e-07 - val_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1002e-04 - accuracy: 0.9912 - val_loss: 1.1554e-07 - val_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0728e-04 - accuracy: 0.9825 - val_loss: 1.1473e-07 - val_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0630e-04 - accuracy: 0.9912 - val_loss: 1.1435e-07 - val_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0692e-04 - accuracy: 0.9825 - val_loss: 1.1192e-07 - val_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0090e-04 - accuracy: 0.9912 - val_loss: 1.1536e-07 - val_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0160e-04 - accuracy: 0.9912 - val_loss: 1.1780e-07 - val_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.0266e-04 - accuracy: 0.9912 - val_loss: 1.1891e-07 - val_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.0367e-04 - accuracy: 0.9912 - val_loss: 1.2035e-07 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4d94a60ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTURQOSzmJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c64095-28cb-429b-a194-4b421630808f"
      },
      "source": [
        "# Chat with chatbot\n",
        "\n",
        "# make bag of words for input text\n",
        "def bag_of_words(s, words):\n",
        "\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "    \n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "            \n",
        "    return np.array(bag)\n",
        "\n",
        "# predict intenet and choose response\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        inp_stopwords = remove_stopwords(inp)\n",
        "        inp_spelling = remove_stopwords(inp_stopwords)\n",
        "        results = model.predict(np.array([bag_of_words(inp_spelling, words)]))\n",
        "        results_index = np.argmax(results)\n",
        "        tag = all_labels[results_index]\n",
        "\n",
        "        for tg in data['intents']:\n",
        "            if tg['intent'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))\n",
        "\n",
        "chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: hello. how are you ?\n",
            "Hola human, please tell me your GeniSys user\n",
            "You: what's your name ?\n",
            "<HUMAN>, what can I do for you?\n",
            "You: no i want your real name?\n",
            "GeniSys\n",
            "You: tell me a joke\n",
            "David Hasselhoff walks into a bar and says to the barman, 'I want you to call me David Hoff'.  The barman replies 'Sure thing Dave... no hassle'\n",
            "You: tell me about self-aware..\n",
            "System says no!\n",
            "You: can you open the door please?\n",
            "I’m sorry, I’m afraid I can’t do that!\n",
            "You: thank you\n",
            "Happy to help!\n",
            "You: goodbye\n",
            "See you later\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwp0Rr_LUZxC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}